def gradientDescent(start,gradient,lr,iterations):
    steps=[start]
    x=start
    for _ in range(iterations):
        diff=lr*gradient(x)
        x=x-diff
        steps.append(x)
    return steps,lr,x

def gradientfunc(x):
    return 2*x+6

start=int(input())
history,lr,lm=gradientDescent(start,gradientfunc,0.01,100)

print("Learning rate of algorithm is:",lr,end="\n")
print("Iterations of algorithm is:",len(history),end="\n")
print("Local minima :",lm)
